Title (refer to HAR)
==============================
```{r, echo=FALSE, results='hide'}
library(caret)
library(ggplot2)
library(lattice)
library(klaR)
library(MASS)

```
You should create a report describing how you built your model, how you used cross validation, what you think the expected out of sample error is, and why you made the choices you did.

## Summary

## Model Construction
set our global seed; this will be relevant if the tangled version of the Rmd is run.  alternatively can set individual seeds for every action that would require them:
```{r}
set.seed(2138)
```

### Obtaining the data
<R code chunk with links, download to data dir; can hide it but refer to it>
```{r, echo=FALSE, eval=FALSE}
#download training/testing datasets and load into R
trainingDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"
testDataURL <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"
if(!file.exists("./data")) {dir.create("./data")}
download.file(trainingDataURL, destfile="./data/WLtrainingData.csv")
download.file(testDataURL, destfile="./data/WLtestData.csv")
dateDownloaded <- date()
```
```{r}
training <- read.csv("./data/WLtrainingData.csv")
test <- read.csv("./data/WLtestData.csv")
```

### Exploration and Pre-processing

Some examination of the dataset reveals a number of features that will be superfluous to our model; our model will attempt to use sensor data to predict a human activity being performed, so first we will clean the data set to remove features that provide no information and/or do not relate to sensor inputs.

#### Cleaning the Data
```{r}
# get the columns that are mostly empty
colpctsNA <- rep(NA, ncol(training))
for(i in 1:ncol(training)){
        colpctsNA[i] <- sum(is.na(training[,i]))/nrow(training)
}
table(colpctsNA)
# keep only the ones that have data in them - 
# others are missing 98% of possible entries
training <- training[,colpctsNA==0]
test <- test[,colpctsNA==0]
```

```{r}
# strip out the factor columns and time/index columns, keeping just the sensor
# columns and the target variable
factorcols <- sapply(training[1,], is.factor)
nonfactorcols <- factorcols[factorcols==FALSE]
keep <- c(names(nonfactorcols)[5:length(names(nonfactorcols))], "classe")
# keep the non-factor columns minus time and index, plus the target variable
training <- training[,keep]
#test <- test[,keep] need to figure out how to deal with this - looks like for problem submission
```

#### Pre-processing

Pre-processing will be done in our training function directly, 

a main thing to do here is probably PCA - high dimensionality of the data may boil down to a small number of PCs.  If analysis doesn't yield anything interesting, can explore alternatives

can also look at some other factors, like structure of the data - lots of factor variables here - what does that imply for our model choice?  maybe something nonlinear would be better.  lots of missing values also.

regularization?  look at lecture on preprocessing and explore options for building some preprocessing into the model

### Cross Validation in our model

how to do this ?  manually, somehow?  or just note that it's being CV'd in the train (or trainControl ?) function?  look through lecture notes

can specify the method in trainControl(method = "cv") etc. - basically i think just note that this was passed (train() will bootstrap by default, but we can use a different method), and write a justification for why we chose what we did

### Explanation of Choices Made 

(maybe part of model construction; subsection - talk about exploratory stuff here and possibly touch upon overfitting)

## The final model - interpretation (?) if possible



## Expectations for Out-of-Sample Error

that the error rate will be higher than what we got on the test set -- more detail than this ?  see lecture notes on out-of-sample error

address overfitting here - what we have done to try to correct for it

## anything else that may be missing from assignment requirements
